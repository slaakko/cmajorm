// =================================
// Copyright (c) 2022 Seppo Laakko
// Distributed under the MIT license
// =================================

using System;
using System.Collections;
using System.Lex;
using shtokens;

private int debugMode = 0;

void SetTokenizerDebugMode()
{
	debugMode = GetDebugMode();
}

public enum TokenFlags : int
{
    none = 0, hasSlash = 1 << 0, hasPatternChar = 1 << 1, hasAssignment = 1 << 2, hasDollar = 1 << 3, hasTilde = 1 << 4, brace = 1 << 5
}

public string TokenFlagStr(TokenFlags flags)
{
    string s;
    if ((flags & TokenFlags.hasSlash) != TokenFlags.none)
    {
        s.Append("hasSlash");
    }
    if ((flags & TokenFlags.hasPatternChar) != TokenFlags.none)
    {
        if (!s.IsEmpty())
        {
            s.Append(" | ");
        }
        s.Append("hasPatternChar");
    }
    if ((flags & TokenFlags.hasAssignment) != TokenFlags.none)
    {
        if (!s.IsEmpty())
        {
            s.Append(" | ");
        }
        s.Append("hasAssignment");
    }
    if ((flags & TokenFlags.hasDollar) != TokenFlags.none)
    {
        if (!s.IsEmpty())
        {
            s.Append(" | ");
        }
        s.Append("hasDollar");
    }
    if ((flags & TokenFlags.hasTilde) != TokenFlags.none)
    {
        if (!s.IsEmpty())
        {
            s.Append(" | ");
        }
        s.Append("hasTilde");
    }
    if ((flags & TokenFlags.brace) != TokenFlags.none)
    {
        if (!s.IsEmpty())
        {
            s.Append(" | ");
        }
        s.Append("brace");
    }
    if (s.IsEmpty())
    {
        s = "none";
    }
    return s;
} 

public class ShellToken
{
    public nothrow ShellToken(int id_, const ustring& match_) : 
        flags(), id(id_), match(match_), line(0), startCol(0), endCol(0)
    {
    }
    public nothrow ShellToken(int id_, const ustring& match_, int line_, int startCol_, int endCol_) : 
        flags(), id(id_), match(match_), line(line_), startCol(startCol_), endCol(endCol_)
    {
    }
    public nothrow const uchar* Begin() const
    {
        return match.Chars();
    }
    public nothrow const uchar* End() const
    {
        return match.Chars() + match.Length();
    }
    public TokenFlags flags;
    public int id;
    public ustring match;
    public int line;
    public int startCol;
    public int endCol;
}

public ustring MakeValue(const List<ShellToken>& tokens)
{
	ustring value;
	for (const ShellToken& token : tokens)
	{
		value.Append(token.match);
	}
	return value;
}

public void SetTokenFlags(ShellToken& token, TokenFlags& globalFlags)
{
    TokenFlags flags = TokenFlags.none;
    uchar* i = token.Begin();
    uchar* e = token.End();
    while (i != e)
    {
        switch (*i)
        {
            case '/':
            {
                flags = cast<TokenFlags>(flags | TokenFlags.hasSlash);
                globalFlags = cast<TokenFlags>(globalFlags | TokenFlags.hasSlash);
                break;
            }
            case '*': case '?': case '[':
            {
                flags = cast<TokenFlags>(flags | TokenFlags.hasPatternChar);
                globalFlags = cast<TokenFlags>(globalFlags | TokenFlags.hasPatternChar);
                break;
            }
            case '=':
            {
                flags = cast<TokenFlags>(flags | TokenFlags.hasAssignment);
                globalFlags = cast<TokenFlags>(globalFlags | TokenFlags.hasAssignment);
                break;
            }
            case '$':
            {
                flags = cast<TokenFlags>(flags | TokenFlags.hasDollar);
                globalFlags = cast<TokenFlags>(globalFlags | TokenFlags.hasDollar);
                break;
            }
            case '~':
            {
                flags = cast<TokenFlags>(flags | TokenFlags.hasTilde);
                globalFlags = cast<TokenFlags>(globalFlags | TokenFlags.hasTilde);
                break;
            }
        }
        ++i;
    }
    if (token.id == LBRACE)
    {
        globalFlags = cast<TokenFlags>(globalFlags | TokenFlags.brace);
    }
    token.flags = flags;
}

List<ShellToken> TokenizeLine(const ustring& line, TokenFlags& globalFlags)
{
    List<ShellToken> tokens;
    shlexer lexer(line.Chars(), line.Chars() + line.Length(), "", 0);
    ++lexer;
    while (*lexer != END)
    {
        if (lexer.token.id >= 0)
        {
            Span span = lexer.GetSpan();
            int startCol;
            int endCol;
            lexer.GetColumns(span, startCol, endCol);
            if (lexer.token.id == TOKEN)
            {
                int kw = lexer.GetKeywordToken(lexer.token.match);
                if (kw != -1)
                {
                    lexer.token.id = kw;
                }
            }
            ShellToken shellToken(lexer.token.id, lexer.token.match.ToString(), lexer.token.line, startCol, endCol);
            SetTokenFlags(shellToken, globalFlags);
            tokens.Add(shellToken);
        }
        ++lexer;
    }
    return tokens;
}

void PrintTokens(const List<ShellToken>& tokens)
{
    for (const ShellToken& token : tokens)
    {
        Terminal.Out() << "(" << TokenFlagStr(token.flags) << " : " << token.id << " : " << GetTokenName(token.id) << " : '" << token.match << "')" << endl();
    }
}

void AddTokens(List<ShellToken>& result, const List<ShellToken>& tokens)
{
    for (const ShellToken& token : tokens)
    {
        result.Add(token);
    }
}

void AddWord(const ShellToken& token, List<ShellToken>& words, bool& brk)
{
    if (!brk && !words.IsEmpty() && words.Back().id == WORD)
    {
        words.Back().match.Append(token.match);
    }
    else
    {
        brk = false;
        ShellToken wordToken(WORD, token.match);
        wordToken.flags = token.flags;
        words.Add(wordToken);
    }
}

void AddQuotedChar(const ShellToken& token, List<ShellToken>& words, bool& brk)
{
    ShellToken chToken(WORD, token.match.Substring(1));
    AddWord(chToken, words, brk);
}

void AddQuotedStr(const ShellToken& token, List<ShellToken>& words, bool& brk)
{
    ShellToken strToken(WORD, token.match.Substring(1, token.match.Length() - 2));
    AddWord(strToken, words, brk);
}

List<ShellToken> MakeWords(const List<ShellToken>& tokens)
{
	SetTokenizerDebugMode();
	if ((debugMode & debugShell) != 0)
	{
		WriteDebugMessage("> sh.tokenizer.make.words");
	}
    bool brk = false;
    List<ShellToken> words;
    TokenLexer lexer(tokens);
    while (*lexer != END)
    {
        switch (*lexer)
        {
            case TOKEN:
            {
				if ((debugMode & debugShell) != 0)
				{
					WriteDebugMessage("> sh.tokenizer.make.words.token");
				}
                AddWord(lexer.CurrentToken(), words, brk);
                break;
            }
            case QUOTED_CHAR:
            {
				if ((debugMode & debugShell) != 0)
				{
					WriteDebugMessage("> sh.tokenizer.make.words.quoted.char");
				}
                AddQuotedChar(lexer.CurrentToken(), words, brk);
                break;
            }
            case SINGLE_QUOTED:
            case DOUBLE_QUOTED:
            {
				if ((debugMode & debugShell) != 0)
				{
					WriteDebugMessage("> sh.tokenizer.make.words.quoted");
				}
                AddQuotedStr(lexer.CurrentToken(), words, brk);
                break;
            }
            case SPACE:
            {
                brk = true;
				if ((debugMode & debugShell) != 0)
				{
					WriteDebugMessage("> sh.tokenizer.make.words.space");
				}
                break;
            }
			case WORD:
			{
				if ((debugMode & debugShell) != 0)
				{
					WriteDebugMessage("> sh.tokenizer.make.words.word");
				}
                AddWord(lexer.CurrentToken(), words, brk);
                break;
			}
            default:
            {
				if ((debugMode & debugShell) != 0)
				{
					WriteDebugMessage("> sh.tokenizer.make.words.default token=" + ToString(lexer.CurrentToken().id));
				}
                words.Add(lexer.CurrentToken());
                break;
            }
        }
        ++lexer;
    }
	if ((debugMode & debugShell) != 0)
	{
		WriteDebugMessage("< sh.tokenizer.make.words.count=" + ToString(words.Count()));
	}
    return words;
}
